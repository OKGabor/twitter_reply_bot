{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvx16TuDVAdl",
        "outputId": "16eee8e8-7079-4133-e495-13d4799d014c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.10/dist-packages (4.14.0)\n",
            "Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.27.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (2.31.0)\n",
            "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install tweepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX0pXrEFdxs5",
        "outputId": "8b04a211-1028-4995-f405-e755c4810711"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ntscraper\n",
            "  Downloading ntscraper-0.3.13-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ntscraper) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from ntscraper) (4.12.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from ntscraper) (4.9.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->ntscraper) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ntscraper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ntscraper) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ntscraper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ntscraper) (2024.7.4)\n",
            "Installing collected packages: ntscraper\n",
            "Successfully installed ntscraper-0.3.13\n"
          ]
        }
      ],
      "source": [
        "!pip install ntscraper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ufLcL6bgD3a",
        "outputId": "baeb5ed9-64f7-4504-eeca-221ba9ba14fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Testing instances: 100%|██████████| 77/77 [01:15<00:00,  1.02it/s]\n",
            "INFO:root:No instance specified, using random instance https://nitter.privacydev.net\n",
            "WARNING:root:Fetching error: Instance has been rate limited.Use another instance or try again later.\n",
            "INFO:root:No instance specified, using random instance https://nitter.privacydev.net\n",
            "WARNING:root:Fetching error: Instance has been rate limited.Use another instance or try again later.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No new tweets to reply to.\n"
          ]
        }
      ],
      "source": [
        "import tweepy\n",
        "from ntscraper import Nitter\n",
        "from google.colab import drive\n",
        "\n",
        "# Step 1: Connect to Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the replied_id.txt file\n",
        "replied_id_file = '/content/drive/My Drive/x_bot/replied_id.txt'\n",
        "\n",
        "# Step 2: Initialize the tweepy Client with your Twitter application credentials\n",
        "client = tweepy.Client(consumer_key=\"YOUR_CONSUMER_KEY\",\n",
        "                       consumer_secret=\"YOUR_CONSUMER_SECRET\",\n",
        "                       access_token=\"YOUR_ACCESS_TOKEN\",\n",
        "                       access_token_secret=\"YOUR_ACCESS_TOKEN_SECRET\")\n",
        "\n",
        "# Step 3: Read the replied_id.txt file\n",
        "def read_replied_ids(file_path):\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            replied_ids = file.read().splitlines()\n",
        "            return replied_ids\n",
        "    except FileNotFoundError:\n",
        "        return []\n",
        "\n",
        "# Step 4: Scrape tweets based on search terms\n",
        "scraper = Nitter()\n",
        "search_terms = [\"term1\", \"term2\"]\n",
        "tweet_ids = []\n",
        "\n",
        "for term in search_terms:\n",
        "    posts = scraper.get_tweets(term, mode='term', number=1000)\n",
        "    for post in posts['tweets']:\n",
        "        if post['stats']['likes'] > 100:\n",
        "            link = post['link']\n",
        "            tweet_id = link.split('/')[-1].split('#')[0]\n",
        "            tweet_ids.append(tweet_id)\n",
        "\n",
        "# Step 5: Filter out already replied tweets\n",
        "replied_ids = read_replied_ids(replied_id_file)\n",
        "new_tweet_ids = [tweet_id for tweet_id in tweet_ids if tweet_id not in replied_ids]\n",
        "\n",
        "# Step 6: Reply to new tweets and update the replied_id.txt file\n",
        "if new_tweet_ids:\n",
        "    with open(replied_id_file, 'a') as file:\n",
        "        for tweet_id in new_tweet_ids:\n",
        "            try:\n",
        "                response = client.create_tweet(text=\"YOUR_REPLY_TEXT\", in_reply_to_tweet_id=tweet_id)\n",
        "                print(f\"Reply posted successfully to tweet ID: {tweet_id}\")\n",
        "                file.write(tweet_id + '\\n')\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to reply to tweet ID: {tweet_id}. Error: {e}\")\n",
        "else:\n",
        "    print(\"No new tweets to reply to.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
